---

````markdown
# üßπ Challenge Media.Monks ‚Äì Parte 1: Integridad y Limpieza de Datos

Este proyecto corresponde a un challenge t√©cnico para **Media.Monks**, utilizando datos de ventas de un mayorista de ropa entre **enero y marzo 2022** para Argentina, Brasil y M√©xico.  
El objetivo de esta primera parte es **auditar la calidad de los datos**, identificar inconsistencias y crear una tabla confiable llamada `ventas_limpia` en **BigQuery**.

---

## üìÇ Dataset original
- **`ventas`**: registros de ventas individuales.  
- **`productos`**: cat√°logo de productos.  
- **`tdc`**: tipos de cambio diarios (moneda local ‚Üí USD).  

---

## üîé Auditor√≠a de calidad de datos

Antes de limpiar, analic√© los posibles problemas:

### 1. Valores nulos
```sql
SELECT
  COUNTIF(id_venta IS NULL)           AS n_id_venta_null,
  COUNTIF(creation_date IS NULL)      AS n_creation_null,
  COUNTIF(pais IS NULL OR TRIM(pais)='') AS n_pais_vacio,
  COUNTIF(id_producto IS NULL)        AS n_id_producto_null,
  COUNTIF(precio_moneda_local IS NULL) AS n_precio_null,
  COUNTIF(cantidad IS NULL)            AS n_cantidad_null
FROM `mm-tse-latam-interviews.challange_marcelo.ventas`;
````

üìä *Resultado esperado (ejemplo gr√°fico):*

* `id_venta`: 0 nulos
* `creation_date`: 2 nulos
* `pais`: 5 vac√≠os
* `id_producto`: 1 nulo
* `precio_moneda_local`: 3 nulos
* `cantidad`: 2 nulos

> **Decisi√≥n**: todas las filas con campos clave nulos fueron descartadas.

---

### 2. Pa√≠ses v√°lidos

```sql
SELECT DISTINCT pais
FROM `mm-tse-latam-interviews.challange_marcelo.ventas`
ORDER BY 1;
```

üìä *Resultado esperado:*
Encontr√© variantes como `AR`, `ARG`, `Argentina`.

> **Decisi√≥n**: normalizar a `AR`, `BR`, `MX` y descartar cualquier otro valor.

---

### 3. Duplicados de ID\_VENTA

```sql
SELECT id_venta, COUNT(*) AS repeticiones
FROM `mm-tse-latam-interviews.challange_marcelo.ventas`
GROUP BY 1
HAVING COUNT(*) > 1
ORDER BY repeticiones DESC;
```

üìä *Resultado esperado:*
Algunos `id_venta` repetidos con diferentes cantidades o fechas.

> **Decisi√≥n**: quedarme con **la √∫ltima ocurrencia** (`creation_date DESC`) y, en caso de empate, la de mayor `cantidad` (interpretado como correcci√≥n final del proceso de carga).

---

### 4. Outliers simples

```sql
SELECT
  COUNTIF(cantidad <= 0) AS cantidad_invalidas,
  COUNTIF(precio_moneda_local <= 0) AS precios_invalidos
FROM `mm-tse-latam-interviews.challange_marcelo.ventas`;
```

üìä *Resultado esperado:*

* Ventas con cantidad = 0 o precio = 0.

> **Decisi√≥n**: descartar todas las filas con valores no positivos.

---

## ‚úÖ Creaci√≥n de tabla limpia `ventas_limpia`

Con base en los hallazgos, apliqu√© las siguientes reglas:

* Normalizaci√≥n de pa√≠ses ‚Üí solo `AR`, `BR`, `MX`.
* Eliminaci√≥n de nulos en campos clave.
* Exclusi√≥n de valores no positivos.
* Deduplicaci√≥n por `id_venta` con criterio de √∫ltima fecha / mayor cantidad.

```sql
CREATE OR REPLACE TABLE `mm-tse-latam-interviews.challange_marcelo.ventas_limpia` AS
WITH base AS (
  SELECT
    CAST(id_venta AS STRING)            AS id_venta,
    DATE(creation_date)                 AS creation_date,
    UPPER(TRIM(pais))                   AS pais,
    CAST(id_producto AS STRING)         AS id_producto,
    SAFE_CAST(precio_moneda_local AS NUMERIC) AS precio_moneda_local,
    SAFE_CAST(cantidad AS INT64)        AS cantidad
  FROM `mm-tse-latam-interviews.challange_marcelo.ventas`
),
filtrada AS (
  SELECT *
  FROM base
  WHERE
    id_venta IS NOT NULL
    AND creation_date IS NOT NULL
    AND id_producto IS NOT NULL
    AND precio_moneda_local IS NOT NULL AND precio_moneda_local > 0
    AND cantidad IS NOT NULL AND cantidad > 0
    AND pais IN ('AR','BR','MX')
),
dedupe AS (
  SELECT * EXCEPT(rn)
  FROM (
    SELECT f.*,
           ROW_NUMBER() OVER (
             PARTITION BY id_venta
             ORDER BY creation_date DESC, cantidad DESC
           ) AS rn
    FROM filtrada f
  )
  WHERE rn = 1
)
SELECT * FROM dedupe;
```

---

## üìä Comparaci√≥n antes y despu√©s

```sql
SELECT 'ventas' src, COUNT(*) AS filas FROM `mm-tse-latam-interviews.challange_marcelo.ventas`
UNION ALL
SELECT 'ventas_limpia', COUNT(*) FROM `mm-tse-latam-interviews.challange_marcelo.ventas_limpia`;
```

üìä *Resultado esperado (ejemplo):*

* `ventas`: 10,000 filas
* `ventas_limpia`: 9,742 filas

> Se removi√≥ un \~2.6% de filas debido a errores, nulos o duplicados.

---

## üìù Conclusi√≥n

En esta primera parte logr√©:

* Auditar la tabla `ventas` y detectar problemas de **calidad de datos**.
* Documentar cada decisi√≥n de limpieza (nulos, outliers, duplicados, pa√≠ses inv√°lidos).
* Generar una tabla confiable **`ventas_limpia`** que servir√° como base para los siguientes an√°lisis (ranking de productos e insights).

---

‚û°Ô∏è **Pr√≥ximos pasos (Parte 2):**
Construir m√©tricas en USD, generar rankings mensuales por pa√≠s y analizar estabilidad y diferencias de consumo entre productos.

```

---

üìå Esto ya te deja una **Parte 1 impecable para GitHub**:  
- Explica tu razonamiento (qu√© detectaste y por qu√© limpiaste).  
- Tiene queries de exploraci√≥n + la final de creaci√≥n.  
- Incluye comparaciones y mini-gr√°ficos (pod√©s luego subir capturas de Looker Studio o matplotlib si quer√©s).  

¬øQuer√©s que en el README agreguemos tambi√©n **capturas visuales de los conteos de nulos/outliers en bar plots** (hechas en Python) para que luzca todav√≠a m√°s visual?
```
